{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "training_corpus = [\n",
    "    \"He read a book\",\n",
    "    \"I read a different book\",\n",
    "    \"He read a book by Danielle\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bigram_model(corpus):\n",
    "    unigram_counts = collections.Counter()\n",
    "    bigram_counts = collections.Counter()\n",
    "    for sentence in corpus:\n",
    "        tokens = sentence.strip().split()\n",
    "        unigram_counts.update(tokens)\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigram = (tokens[i], tokens[i+1])\n",
    "            bigram_counts[bigram] += 1\n",
    "    return unigram_counts, bigram_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_probability(sentence, unigram_counts, bigram_counts, smoothing=False, V=None):\n",
    "    tokens = sentence.strip().split()\n",
    "    prob = 1.0\n",
    "    for i in range(len(tokens) - 1):\n",
    "        w1 = tokens[i]\n",
    "        w2 = tokens[i+1]\n",
    "        if smoothing:\n",
    "            count_bigram = bigram_counts.get((w1, w2), 0)\n",
    "            count_w1 = unigram_counts.get(w1, 0)\n",
    "            prob *= (count_bigram + 1) / (count_w1 + V)\n",
    "        else:\n",
    "            count_bigram = bigram_counts.get((w1, w2), 0)\n",
    "            if count_bigram == 0:\n",
    "                return 0.0 \n",
    "            count_w1 = unigram_counts[w1]\n",
    "            prob *= count_bigram / count_w1\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsmoothed Bigram Probability: 0.111111\n",
      "Smoothed Bigram Probability (Add-One): 1.319181e-04\n"
     ]
    }
   ],
   "source": [
    "unigram_counts, bigram_counts = train_bigram_model(training_corpus)\n",
    "test_sentence = \"I read a different book by Danielle\"\n",
    "unsmoothed_prob = sentence_probability(test_sentence, unigram_counts, bigram_counts, smoothing=False)\n",
    "print(\"Unsmoothed Bigram Probability: {:.6f}\".format(unsmoothed_prob))\n",
    "V = len(unigram_counts)\n",
    "smoothed_prob = sentence_probability(test_sentence, unigram_counts, bigram_counts, smoothing=True, V=V)\n",
    "print(\"Smoothed Bigram Probability (Add-One): {:.6e}\".format(smoothed_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
